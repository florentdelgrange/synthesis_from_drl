{"self": "<wasserstein_mdp.WassersteinMarkovDecisionProcess object at 0x2b744f65f670>", "action_shape": "(4,)", "reward_shape": "(1,)", "label_shape": "(2,)", "discretize_action_space": "False", "state_encoder_network": "ModelArchitecture(hidden_units=(128, 128), activation='elu', output_dim=None, input_dim=None, name=None, batch_norm=False, filters=None, kernel_size=None, strides=None, padding=None, raw_last=False, transpose=False)", "action_decoder_network": "None", "transition_network": "ModelArchitecture(hidden_units=(128, 128), activation='elu', output_dim=None, input_dim=None, name=None, batch_norm=False, filters=None, kernel_size=None, strides=None, padding=None, raw_last=True, transpose=False)", "reward_network": "ModelArchitecture(hidden_units=(128, 128), activation='elu', output_dim=None, input_dim=None, name=None, batch_norm=False, filters=None, kernel_size=None, strides=None, padding=None, raw_last=True, transpose=False)", "decoder_network": "ModelArchitecture(hidden_units=(128, 128), activation='elu', output_dim=None, input_dim=None, name=None, batch_norm=False, filters=None, kernel_size=None, strides=None, padding=None, raw_last=True, transpose=False)", "latent_policy_network": "None", "steady_state_lipschitz_network": "ModelArchitecture(hidden_units=(128, 128), activation='elu', output_dim=None, input_dim=None, name=None, batch_norm=False, filters=None, kernel_size=None, strides=None, padding=None, raw_last=True, transpose=False)", "transition_loss_lipschitz_network": "ModelArchitecture(hidden_units=(128, 128), activation='elu', output_dim=None, input_dim=None, name=None, batch_norm=False, filters=None, kernel_size=None, strides=None, padding=None, raw_last=True, transpose=False)", "latent_state_size": "12", "number_of_discrete_actions": "None", "action_encoder_network": "None", "state_encoder_pre_processing_network": "[None, ModelArchitecture(hidden_units=None, activation='relu', output_dim=None, input_dim=None, name=None, batch_norm=False, filters=[64, 32, 16], kernel_size=[3, 3, 3], strides=[2, 1, 1], padding=['valid', 'valid', 'valid'], raw_last=True, transpose=False), None, None]", "state_decoder_post_processing_network": "None", "time_stacked_states": "False", "state_encoder_temperature": "0.6666666", "state_prior_temperature": "0.3333333", "action_encoder_temperature": "None", "latent_policy_temperature": "None", "wasserstein_regularizer_scale_factor": "WassersteinRegularizerScaleFactor(global_scaling=None, global_gradient_penalty_multiplier=10.0, steady_state_scaling=10.0, steady_state_gradient_penalty_multiplier=None, local_transition_loss_scaling=10.0, local_transition_loss_gradient_penalty_multiplier=None)", "encoder_temperature_decay_rate": "0.0", "prior_temperature_decay_rate": "0.0", "reset_state_label": "True", "minimizer": "None", "maximizer": "None", "encoder_optimizer": "None", "entropy_regularizer_scale_factor": "0.0", "entropy_regularizer_decay_rate": "0.0", "entropy_regularizer_scale_factor_min_value": "0.0", "importance_sampling_exponent": "1.0", "importance_sampling_exponent_growth_rate": "0.0", "time_stacked_lstm_units": "128", "reward_bounds": "None", "latent_stationary_network": "None", "action_entropy_regularizer_scaling": "0.0", "enforce_upper_bound": "False", "squared_wasserstein": "False", "n_critic": "5", "trainable_prior": "False", "state_encoder_type": "EncodingType.DETERMINISTIC", "policy_based_decoding": "False", "deterministic_state_embedding": "True", "state_encoder_softclipping": "False", "external_latent_policy": "None", "input_name": "('label', 'pacman_observation', 'pacman_position', 'power_up')", "input_state_component_concat_units": "[32]", "cost_fn": "{'state': ('l22', 'l22', 'l22', 'l22'), 'reward': 'l2'}", "cost_weights": "{'state': (1.0, 1.0, 1.0, 1.0), 'reward': 10.0}", "use_batch_norm": "False", "summary": "False", "args": "()", "kwargs": "{'args': (), 'kwargs': {}}", "state_shape": "[(2,), (32, 32, 3), (2,), (2,)]", "__class__": "<class 'wasserstein_mdp.WassersteinMarkovDecisionProcess'>", "eval_policy": "1.5544306", "training_step": "730000"}